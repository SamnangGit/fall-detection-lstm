{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1c2a0d",
   "metadata": {},
   "source": [
    "# Video Feature Extraction using Mediapipe Pose\n",
    "\n",
    "This notebook extracts pose keypoints (features) from videos located in specified `train_data` and `test_data` folders using Mediapipe Pose.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Setup:** Install compatible librarie using settings.\n",
    "2.  **Preprocessing Functions:** Define functions to extract keypoints from a video and process folders.\n",
    "3.  **Feature Extraction:** Run the extraction process on all videos in the specified train and test directories, saving the results as `.pkl` files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup Environment - Install Compatible Libraries, Mount Drive & Import\n",
    "\n",
    "Installs necessary and compatible library versions (pinning NumPy), mounts Google Drive, and imports required modules. \n",
    "\n",
    "**IMPORTANT:** After running this cell the first time, **RESTART THE RUNTIME** using the menu (`Runtime` -> `Restart Runtime`), then **RUN THIS CELL AGAIN** before proceeding to Cell 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5256cd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FeatureExtract_Setup_Cell"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Setup Environment - Install Compatible Libraries, Mount Drive & Import\n",
    "\n",
    "# Uninstall potentially conflicting libraries first for a cleaner state\n",
    "print(\"Uninstalling potentially conflicting libraries...\")\n",
    "!pip uninstall numpy torch torchvision torchaudio mediapipe opencv-python -y\n",
    "\n",
    "print(\"\\nInstalling specific NumPy version...\")\n",
    "!pip install --no-cache-dir --force-reinstall numpy\n",
    "\n",
    "print(\"\\nInstalling other libraries without dependency changes...\")\n",
    "!pip install --no-cache-dir --no-dependencies torch torchvision torchaudio mediapipe opencv-python\n",
    "\n",
    "print(\"\\nLibrary installation attempt finished.\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- Code below will run AFTER restarting and running this cell again ---\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "\n",
    "# Import necessary libraries (now that installations should be correct)\n",
    "print(\"\\nImporting libraries...\")\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "print(\"Required libraries for feature extraction imported.\")\n",
    "\n",
    "# Check crucial versions\n",
    "try:\n",
    "    print(f\"\\nUsing NumPy version: {np.__version__}\")\n",
    "    print(f\"Using Mediapipe version: {mp.__version__}\")\n",
    "    # Check if the NumPy version is the one we intended\n",
    "    if np.__version__.startswith('1.26'):\n",
    "        print(\"\\nNumPy version 1.26.x successfully loaded.\")\n",
    "    else:\n",
    "        print(f\"\\nWARNING: NumPy version is {np.__version__}, not 1.26.x! Dependency conflict might still exist or restart was missed.\")\n",
    "except NameError:\n",
    "    print(\"\\nLibraries not fully imported yet (expected on first run before restart). Please follow restart instructions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration - Define Paths and Hyperparameters\n",
    "\n",
    "Set up all the configuration variables: paths to your `train_data` and `test_data` folders, the output directory for features, class names, and feature extraction settings (frame skip, sequence length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FeatureExtract_Config_Cell"
   },
   "outputs": [],
   "source": [
    "# --- User Defined Paths ---\n",
    "# !! IMPORTANT: Update BASE_DRIVE_PATH if your 'dataset' folder is located elsewhere in Drive !!\n",
    "BASE_DRIVE_PATH = '/content/drive/MyDrive/dataset' # Main folder in your Drive containing train_data and test_data\n",
    "\n",
    "#  Noted that, I have change the flow abit. This train and test data will be combined together after extract the feature and keep in the same directory.\n",
    "# The train and test will be splited during training phase\n",
    "TRAIN_DATA_DIR = os.path.join(BASE_DRIVE_PATH, 'train_data')\n",
    "TEST_DATA_DIR = os.path.join(BASE_DRIVE_PATH, 'test_data')\n",
    "\n",
    "# Class folder names (should be consistent within train_data and test_data)\n",
    "# !! IMPORTANT: Update CLASS_FOLDERS if your class names are different !!\n",
    "CLASS_FOLDERS = [\"backward_fall\", \"forward_fall\", \"side_fall\", \"non_fall\"]\n",
    "\n",
    "# Output directories (relative to BASE_DRIVE_PATH)\n",
    "FEATURES_OUTPUT_DIR = os.path.join(BASE_DRIVE_PATH, 'processed_features') # Combined features folder\n",
    "\n",
    "# --- Preprocessing Settings ---\n",
    "FRAME_SKIP = 3  # Extract every Nth frame (e.g., 3 means ~10fps from 30fps, or ~20fps from 60fps)\n",
    "SEQUENCE_LENGTH = 30 # Fixed number of frames (keypoint sequences) per video sample\n",
    "INPUT_SIZE = 33 * 3  # 33 landmarks * 3 coordinates (x, y, visibility) - Needed for padding\n",
    "\n",
    "# --- Create output directories if they don't exist ---\n",
    "print(f\"Creating base feature output directory: {FEATURES_OUTPUT_DIR}\")\n",
    "os.makedirs(FEATURES_OUTPUT_DIR, exist_ok=True)\n",
    "# Create class subdirectories within features directory if they don't exist\n",
    "print(\"Creating class subdirectories for features...\")\n",
    "for class_name in CLASS_FOLDERS:\n",
    "    os.makedirs(os.path.join(FEATURES_OUTPUT_DIR, class_name), exist_ok=True)\n",
    "\n",
    "# --- Define class to index mapping (needed for process_data_folder, though labels aren't used later) ---\n",
    "label_map = {name: i for i, name in enumerate(CLASS_FOLDERS)}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Base Path: {BASE_DRIVE_PATH}\")\n",
    "print(f\"  Train Data Path: {TRAIN_DATA_DIR}\")\n",
    "print(f\"  Test Data Path: {TEST_DATA_DIR}\")\n",
    "print(f\"  Feature Output Path: {FEATURES_OUTPUT_DIR}\")\n",
    "print(f\"  Classes: {CLASS_FOLDERS}\")\n",
    "print(f\"  Frame Skip: {FRAME_SKIP}\")\n",
    "print(f\"  Sequence Length: {SEQUENCE_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Preprocessing Function Definitions\n",
    "\n",
    "Initializes the Mediapipe Pose model and defines the helper functions:\n",
    "*   `extract_keypoints_from_video`: Extracts pose landmarks from a video file, handling padding/truncation.\n",
    "*   `process_data_folder`: Iterates through class folders, processes each video using the above function, and saves the extracted keypoint sequence as a `.pkl` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeatureExtract_Preprocessing_Funcs"
   },
   "outputs": [],
   "source": [
    "# Initialize Mediapipe Pose\n",
    "print(\"Initializing Mediapipe Pose...\")\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, # Process video stream\n",
    "                    model_complexity=1,      # 0, 1, 2 (higher is more accurate but slower)\n",
    "                    smooth_landmarks=True,\n",
    "                    enable_segmentation=False,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# mp_drawing = mp.solutions.drawing_utils # Not needed for feature extraction only\n",
    "\n",
    "def extract_keypoints_from_video(video_path, frame_skip, sequence_length):\n",
    "    \"\"\"\n",
    "    Extracts Mediapipe keypoints from a video file. Handles sequence padding/truncation.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return None\n",
    "\n",
    "    frame_count = 0\n",
    "    keypoints_sequence = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success: break # End of video\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            try:\n",
    "                # Convert the BGR image to RGB.\n",
    "                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                # To improve performance, optionally mark the image as not writeable to\n",
    "                # pass by reference.\n",
    "                image_rgb.flags.writeable = False\n",
    "                # Process the image and find pose landmarks.\n",
    "                results = pose.process(image_rgb)\n",
    "                # image_rgb.flags.writeable = True # No drawing needed\n",
    "\n",
    "                if results.pose_landmarks:\n",
    "                    frame_keypoints = []\n",
    "                    for landmark in results.pose_landmarks.landmark:\n",
    "                        # Store x, y, visibility\n",
    "                        frame_keypoints.extend([landmark.x, landmark.y, landmark.visibility])\n",
    "                    keypoints_sequence.append(frame_keypoints)\n",
    "                else:\n",
    "                    # Pad with zeros if no pose detected in a frame\n",
    "                    keypoints_sequence.append(np.zeros(INPUT_SIZE).tolist())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing frame {frame_count} in {video_path}: {e}\")\n",
    "                # Pad with zeros on error\n",
    "                keypoints_sequence.append(np.zeros(INPUT_SIZE).tolist())\n",
    "\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "\n",
    "    num_extracted_frames = len(keypoints_sequence)\n",
    "    if num_extracted_frames == 0:\n",
    "        print(f\"Warning: No keypoints extracted from {video_path}\")\n",
    "        return None # Return None if video was empty or unreadable\n",
    "\n",
    "    # Pad or truncate the sequence to the desired sequence_length\n",
    "    final_sequence = np.zeros((sequence_length, INPUT_SIZE), dtype=np.float32)\n",
    "\n",
    "    if num_extracted_frames >= sequence_length:\n",
    "        # Truncate if too long\n",
    "        final_sequence = np.array(keypoints_sequence[:sequence_length], dtype=np.float32)\n",
    "    else:\n",
    "        # Pad with zeros if too short\n",
    "        sequence_array = np.array(keypoints_sequence, dtype=np.float32)\n",
    "        final_sequence[:num_extracted_frames] = sequence_array\n",
    "\n",
    "    return final_sequence\n",
    "\n",
    "\n",
    "def process_data_folder(data_directory, class_folders, label_map, feature_output_dir):\n",
    "    \"\"\"Processes videos in a given directory (train or test) and saves features.\"\"\"\n",
    "    processed_files_count = 0\n",
    "    skipped_files_count = 0\n",
    "    failed_files_count = 0\n",
    "    print(f\"\\nStarting processing for data source: {data_directory}\")\n",
    "\n",
    "    for class_name in class_folders:\n",
    "        class_label = label_map[class_name]\n",
    "        video_folder_abs = os.path.join(data_directory, class_name)\n",
    "        # Features are saved in a common structure under FEATURES_OUTPUT_DIR\n",
    "        feature_class_dir = os.path.join(feature_output_dir, class_name)\n",
    "\n",
    "        print(f\"\\n  Processing class folder: {class_name}\")\n",
    "        print(f\"    Video source folder: {video_folder_abs}\")\n",
    "        print(f\"    Feature output folder: {feature_class_dir}\")\n",
    "\n",
    "        # Find video files (e.g., .mp4, .avi)\n",
    "        video_files = []\n",
    "        # Add common video extensions\n",
    "        for ext in ('*.mp4', '*.avi', '*.mov', '*.wmv', '*.mkv', '*.flv'):\n",
    "             video_files.extend(glob.glob(os.path.join(video_folder_abs, ext)))\n",
    "             video_files.extend(glob.glob(os.path.join(video_folder_abs, ext.upper()))) # Also check uppercase extensions\n",
    "\n",
    "        video_files = sorted(list(set(video_files))) # Sort and remove potential duplicates\n",
    "\n",
    "        if not video_files:\n",
    "            print(f\"    Warning: No video files found in {video_folder_abs}\")\n",
    "            continue\n",
    "\n",
    "        num_videos = len(video_files)\n",
    "        print(f\"    Found {num_videos} videos.\")\n",
    "\n",
    "        for idx, video_path in enumerate(video_files):\n",
    "            video_filename = os.path.basename(video_path)\n",
    "            feature_filename = os.path.splitext(video_filename)[0] + '.pkl'\n",
    "            feature_save_path = os.path.join(feature_class_dir, feature_filename)\n",
    "\n",
    "            # Check if features already exist\n",
    "            if os.path.exists(feature_save_path):\n",
    "                print(f\"({idx+1}/{num_videos}) Skipping {video_filename}, features already exist.\")\n",
    "                skipped_files_count += 1\n",
    "                continue\n",
    "\n",
    "            print(f\"    ({idx+1}/{num_videos}) Processing {video_filename}...\")\n",
    "            keypoints_data = extract_keypoints_from_video(video_path, FRAME_SKIP, SEQUENCE_LENGTH)\n",
    "\n",
    "            if keypoints_data is not None:\n",
    "                try:\n",
    "                    with open(feature_save_path, 'wb') as f:\n",
    "                        pickle.dump(keypoints_data, f)\n",
    "                    print(f\"Saved features to {feature_save_path}\")\n",
    "                    processed_files_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"      Error saving features for {video_filename}: {e}\")\n",
    "                    failed_files_count += 1\n",
    "            else:\n",
    "                print(f\"Failed to extract features for {video_filename}. Skipping.\")\n",
    "                failed_files_count += 1\n",
    "\n",
    "    print(f\"\\nFinished processing {data_directory}\")\n",
    "    print(f\"  Successfully processed: {processed_files_count} files\")\n",
    "    print(f\"  Skipped (already exist): {skipped_files_count} files\")\n",
    "    print(f\"  Failed (extraction/saving): {failed_files_count} files\")\n",
    "    return processed_files_count, skipped_files_count, failed_files_count\n",
    "\n",
    "print(\"Mediapipe Pose initialized and helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Feature Extraction Execution\n",
    "\n",
    "This cell runs the main feature extraction process. It calls `process_data_folder` for both the `TRAIN_DATA_DIR` and `TEST_DATA_DIR` specified in Cell 2. This will populate the `FEATURES_OUTPUT_DIR` with `.pkl` files containing the extracted keypoint sequences for all videos found. It also times the process and reports the counts of processed, skipped, and failed files. Finally, it closes the Mediapipe `pose` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FeatureExtract_Execution"
   },
   "outputs": [],
   "source": [
    "# --- Main Preprocessing Execution ---\n",
    "print(\"\\nStarting Feature Extraction Process...\")\n",
    "overall_start_time = time.time()\n",
    "total_processed = 0\n",
    "total_skipped = 0\n",
    "total_failed = 0\n",
    "\n",
    "# Process Training Data Directory\n",
    "if os.path.isdir(TRAIN_DATA_DIR):\n",
    "    processed, skipped, failed = process_data_folder(\n",
    "        TRAIN_DATA_DIR,\n",
    "        CLASS_FOLDERS,\n",
    "        label_map,\n",
    "        FEATURES_OUTPUT_DIR\n",
    "    )\n",
    "    total_processed += processed\n",
    "    total_skipped += skipped\n",
    "    total_failed += failed\n",
    "else:\n",
    "    print(f\"\\nWarning: Train data directory not found: {TRAIN_DATA_DIR}\")\n",
    "\n",
    "# Process Testing Data Directory\n",
    "if os.path.isdir(TEST_DATA_DIR):\n",
    "    processed, skipped, failed = process_data_folder(\n",
    "        TEST_DATA_DIR,\n",
    "        CLASS_FOLDERS,\n",
    "        label_map,\n",
    "        FEATURES_OUTPUT_DIR\n",
    "    )\n",
    "    total_processed += processed\n",
    "    total_skipped += skipped\n",
    "    total_failed += failed\n",
    "else:\n",
    "    print(f\"\\nWarning: Test data directory not found: {TEST_DATA_DIR}\")\n",
    "\n",
    "overall_end_time = time.time()\n",
    "print(f\"\\n--------------------------------------------------\")\n",
    "print(f\"Overall Feature Extraction Summary:\")\n",
    "print(f\"  Total time taken: {overall_end_time - overall_start_time:.2f} seconds.\")\n",
    "print(f\"  Total files processed successfully: {total_processed}\")\n",
    "print(f\"  Total files skipped (features existed): {total_skipped}\")\n",
    "print(f\"  Total files failed (extraction/saving): {total_failed}\")\n",
    "print(f\"  Features saved in subfolders under: {FEATURES_OUTPUT_DIR}\")\n",
    "print(f\"--------------------------------------------------\")\n",
    "\n",
    "# Close the pose object when done\n",
    "print(\"\\nClosing Mediapipe Pose object...\")\n",
    "try:\n",
    "    pose.close()\n",
    "    print(\"Mediapipe Pose object closed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error closing pose object (might have already been closed or not initialized): {e}\")\n",
    "\n",
    "print(\"\\n--- Feature Extraction Script Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
